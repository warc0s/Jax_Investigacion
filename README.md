# ğŸš€ InvestigaciÃ³n Comparativa: JAX vs TensorFlow vs PyTorch

![JAX Tensorflow Pytorch](https://www.askpython.com/wp-content/uploads/2021/03/front_cover-1024x512.png.webp)

Este proyecto explora **JAX**, una potente biblioteca de computaciÃ³n numÃ©rica de Google, y la compara con otros frameworks populares como TensorFlow y PyTorch. El objetivo principal es evaluar el rendimiento y la eficiencia de JAX en tareas de aprendizaje automÃ¡tico.

## ğŸ“š Ãndice
1. [Estructura ](#-estructura)
1. [Â¿QuÃ© es JAX?](#-quÃ©-es-jax)
2. [ComparaciÃ³n con TensorFlow y PyTorch](#-comparaciÃ³n-jax-vs-tensorflow-vs-pytorch)
3. [Ecosistema JAX](#-ecosistema-jax)
4. [Experimento PrÃ¡ctico](#-experimento-prÃ¡ctico)
5. [Resultados y Conclusiones](#-resultados-y-conclusiones)
6. [Recursos Utilizados](#-recursos-utilizados)

---

## ğŸ¢ Estructura

- **JAX_Trabajo_Investigacion_MGE.ipynb:**  
  Notebook principal que detalla el desarrollo de la investigaciÃ³n, incluyendo teorÃ­a, comparaciones y ejemplos prÃ¡cticos.

- **models/:**  
  Directorio que almacena los modelos entrenados y los tiempos de entrenamiento correspondientes. Contiene los siguientes archivos:
  - **jax_params.joblib:** ParÃ¡metros del modelo entrenado con JAX.
  - **jax_time.joblib:** Tiempo de entrenamiento del modelo con JAX.
  - **preprocessor.joblib:** Pipeline de preprocesamiento de datos utilizado en el proyecto.
  - **tf_model.keras:** Modelo entrenado con TensorFlow.
  - **tf_time.joblib:** Tiempo de entrenamiento del modelo con TensorFlow.
  - **torch_model.pth:** Modelo entrenado con PyTorch.
  - **torch_time.joblib:** Tiempo de entrenamiento del modelo con PyTorch.

## ğŸ§  Â¿QuÃ© es JAX?
Framework de Google para **cÃ³mputo numÃ©rico acelerado** con:
- âœ… DiferenciaciÃ³n automÃ¡tica de alto orden
- âœ… CompilaciÃ³n JIT (Just-In-Time)
- âœ… ProgramaciÃ³n funcional pura
- âœ… Soporte nativo para GPU/TPU

*Detalles completos en el [Jupyter Notebook](JAX_Trabajo_Investigacion_MGE.ipynb)*

---

## ğŸ¥Š ComparaciÃ³n: JAX vs TensorFlow vs PyTorch

| CaracterÃ­stica       | JAX ğŸï¸          | TensorFlow ğŸ—ï¸     | PyTorch ğŸ”¥        |
|----------------------|----------------|-------------------|------------------|
| Paradigma            | Funcional      | HÃ­brido           | Imperativo       |
| Entrenamiento (CPU)    | **7 segundos** | 220 segundos      | 17 segundos      |
| AutodiferenciaciÃ³n   | Hessianas      | Gradient Tape     | Autograd         |
| Caso ideal           | InvestigaciÃ³n  | ProducciÃ³n        | Prototipado      |

**Punto clave:**  
JAX brilla en velocidad (7x mÃ¡s rÃ¡pido que PyTorch, 31x que TensorFlow en nuestro test) gracias a XLA y JIT.

---

## ğŸŒ Ecosistema JAX
LibrerÃ­as clave que potencian su uso:
- **Flax/Haiku** â†’ ConstrucciÃ³n de redes neuronales
- **Optax** â†’ Optimizadores avanzados
- **JAX-MD** â†’ Simulaciones cientÃ­ficas
- **NumPyro** â†’ ProgramaciÃ³n probabilÃ­stica

IntegraciÃ³n con: TensorFlow Datasets ğŸ¤ HuggingFace Transformers ğŸ¤ JAX AI Stack

---

## ğŸ”¬ Experimento PrÃ¡ctico
### Bank Marketing Dataset (ClasificaciÃ³n binaria)

**Flujo del experimento:**
1. Preprocesamiento con scikit-learn
2. Entrenamiento idÃ©ntico en 3 frameworks
3. ComparaciÃ³n de tiempos y cÃ³digo

---

## ğŸ“Š Resultados y Conclusiones

- âš¡ JAX fue **el mÃ¡s rÃ¡pido**: 7s vs 17s (PyTorch) y 220s (TensorFlow)
- âœï¸ Sintaxis concisa y estilo funcional, aunque con mÃ¡s lineas de cÃ³digo
- ğŸ§  Ideal para investigaciÃ³n cientÃ­fica y optimizaciones complejas
- ğŸš§ Menor soporte para despliegue en producciÃ³n vs TensorFlow

---

## ğŸ“– Recursos Utilizados
- https://es.statisticseasily.com/glosario/what-is-jax-high-performance-computing/
- https://opensource.googleblog.com/2024/12/a-robust-open-ecosystem-accelerating-ai-infrastructure.html
- https://github.com/jax-ml/jax-ai-stack
- https://github.com/n2cholas/awesome-jax

---

âŒ¨ï¸ **Nota:** Todos los experimentos se ejecutaron en CPU usando Google Colab.  
ğŸ” Â¡Revisa el [Jupyter Notebook](JAX_Trabajo_Investigacion_MGE.ipynb) para detalles tÃ©cnicos y anÃ¡lisis completo!
